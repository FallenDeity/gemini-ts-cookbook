{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini API: Analyze a Video - Historic Event Recognition\n",
    "\n",
    "This notebook shows how you can use Gemini models' multimodal capabilities to recognize which historic event is happening in the video.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Install the Google GenAI SDK\n",
    "\n",
    "Install the Google GenAI SDK from [npm](https://www.npmjs.com/package/@google/genai). \n",
    "\n",
    "```bash\n",
    "$ npm install @google/genai\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup your API key\n",
    "\n",
    "You can [create](https://aistudio.google.com/app/apikey) your API key using Google AI Studio with a single click.\n",
    "\n",
    "Remember to treat your API key like a password. Don't accidentally save it in a notebook or source file you later commit to GitHub. In this notebook we will be storing the API key in a `.env` file. You can also set it as an environment variable or use a secret manager. \n",
    "\n",
    "Here's how to set it up in a `.env` file:\n",
    "\n",
    "```bash\n",
    "$ touch .env\n",
    "$ echo \"GEMINI_API_KEY=<YOUR_API_KEY>\" >> .env\n",
    "```\n",
    "\n",
    ":::{.callout-tip}\n",
    "\n",
    "Another option is to set the API key as an environment variable. You can do this in your terminal with the following command:\n",
    "\n",
    "```bash\n",
    "$ export GEMINI_API_KEY=\"<YOUR_API_KEY>\"\n",
    "```\n",
    ":::\n",
    "\n",
    "### Load the API key\n",
    "\n",
    "To load the API key from the `.env` file, we will use the `dotenv` package. This package loads environment variables from a `.env` file into `process.env`. \n",
    "\n",
    "```bash\n",
    "$ npm install dotenv\n",
    "```\n",
    "\n",
    "Then, we can load the API key in our code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GEMINI_API_KEY is set in the environment variables\n"
     ]
    }
   ],
   "source": [
    "const dotenv = require(\"dotenv\") as typeof import(\"dotenv\");\n",
    "\n",
    "dotenv.config({\n",
    "  path: \"../.env\",\n",
    "});\n",
    "\n",
    "const GEMINI_API_KEY = process.env.GEMINI_API_KEY ?? \"\";\n",
    "if (!GEMINI_API_KEY) {\n",
    "  throw new Error(\"GEMINI_API_KEY is not set in the environment variables\");\n",
    "}\n",
    "console.log(\"GEMINI_API_KEY is set in the environment variables\");\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{.callout-note}\n",
    "In our particular case the `.env` is is one directory up from the notebook, hence we need to use `../` to go up one directory. If the `.env` file is in the same directory as the notebook, you can omit it altogether. \n",
    "\n",
    "```\n",
    "\u2502\n",
    "\u251c\u2500\u2500 .env\n",
    "\u2514\u2500\u2500 examples\n",
    "    \u2514\u2500\u2500 Analyze_a_Video_Historic_Event_Recognition.ipynb\n",
    "```\n",
    ":::\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize SDK Client\n",
    "\n",
    "With the new SDK, now you only need to initialize a client with you API key (or OAuth if using [Vertex AI](https://cloud.google.com/vertex-ai)). The model is now set in each call.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "const google = require(\"@google/genai\") as typeof import(\"@google/genai\");\n",
    "\n",
    "const ai = new google.GoogleGenAI({ apiKey: GEMINI_API_KEY });\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a model\n",
    "\n",
    "Now select the model you want to use in this guide, either by selecting one in the list or writing it down. Keep in mind that some models, like the 2.5 ones are thinking models and thus take slightly more time to respond (cf. [thinking notebook](quickstarts/Get_started_thinking.ipynb) for more details and in particular learn how to switch the thiking off).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "const tslab = require(\"tslab\") as typeof import(\"tslab\");\n",
    "\n",
    "const MODEL_ID = \"gemini-2.5-flash-preview-05-20\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "This example uses [video of President Ronald Reagan's Speech at the Berlin Wall](https://s3.amazonaws.com/NARAprodstorage/opastorage/live/16/147/6014716/content/presidential-libraries/reagan/5730544/6-12-1987-439.mp4) taken on June 12 1987.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "const fs = require(\"fs\") as typeof import(\"fs\");\n",
    "const path = require(\"path\") as typeof import(\"path\");\n",
    "\n",
    "const downloadFile = async (url: string, filePath: string) => {\n",
    "  const response = await fetch(url);\n",
    "  if (!response.ok) {\n",
    "    throw new Error(`Failed to download file: ${response.statusText}`);\n",
    "  }\n",
    "  fs.mkdirSync(path.dirname(filePath), { recursive: true });\n",
    "  const buffer = await response.blob();\n",
    "  const bufferData = Buffer.from(await buffer.arrayBuffer());\n",
    "  fs.writeFileSync(filePath, bufferData);\n",
    "};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "const VIDEO_URL =\n",
    "  \"https://s3.amazonaws.com/NARAprodstorage/opastorage/live/16/147/6014716/content/presidential-libraries/reagan/5730544/6-12-1987-439.mp4\";\n",
    "const VIDEO_FILE_PATH = path.join(\"../assets/examples\", \"Reagan_Berlin_Wall.mp4\");\n",
    "await downloadFile(VIDEO_URL, VIDEO_FILE_PATH);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the file using the File API so its easier to pass it to the model later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { File, FileState } from \"@google/genai\";\n",
    "\n",
    "async function deferredFileUpload(filePath: string, config: { displayName: string }): Promise<File> {\n",
    "  const file = await ai.files.upload({\n",
    "    file: filePath,\n",
    "    config,\n",
    "  });\n",
    "  let getFile = await ai.files.get({ name: file.name ?? \"\" });\n",
    "  while (getFile.state === FileState.PROCESSING) {\n",
    "    getFile = await ai.files.get({ name: file.name ?? \"\" });\n",
    "    console.log(`current file status (${getFile.displayName}): ${getFile.state ?? \"unknown\"}`);\n",
    "    console.log(\"File is still processing, retrying in 5 seconds\");\n",
    "\n",
    "    await new Promise((resolve) => {\n",
    "      setTimeout(resolve, 5000);\n",
    "    });\n",
    "  }\n",
    "  if (file.state === FileState.FAILED) {\n",
    "    throw new Error(\"File processing failed.\");\n",
    "  }\n",
    "  return file;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current file status (President Reagan's Speech at the Berlin Wall): PROCESSING\n",
      "File is still processing, retrying in 5 seconds\n",
      "current file status (President Reagan's Speech at the Berlin Wall): PROCESSING\n",
      "File is still processing, retrying in 5 seconds\n",
      "current file status (President Reagan's Speech at the Berlin Wall): PROCESSING\n",
      "File is still processing, retrying in 5 seconds\n",
      "current file status (President Reagan's Speech at the Berlin Wall): PROCESSING\n",
      "File is still processing, retrying in 5 seconds\n",
      "current file status (President Reagan's Speech at the Berlin Wall): PROCESSING\n",
      "File is still processing, retrying in 5 seconds\n",
      "current file status (President Reagan's Speech at the Berlin Wall): PROCESSING\n",
      "File is still processing, retrying in 5 seconds\n",
      "current file status (President Reagan's Speech at the Berlin Wall): PROCESSING\n",
      "File is still processing, retrying in 5 seconds\n",
      "current file status (President Reagan's Speech at the Berlin Wall): PROCESSING\n",
      "File is still processing, retrying in 5 seconds\n",
      "current file status (President Reagan's Speech at the Berlin Wall): PROCESSING\n",
      "File is still processing, retrying in 5 seconds\n",
      "current file status (President Reagan's Speech at the Berlin Wall): PROCESSING\n",
      "File is still processing, retrying in 5 seconds\n",
      "current file status (President Reagan's Speech at the Berlin Wall): ACTIVE\n",
      "File is still processing, retrying in 5 seconds\n"
     ]
    }
   ],
   "source": [
    "const videoFile = await deferredFileUpload(VIDEO_FILE_PATH, {\n",
    "  displayName: \"President Reagan's Speech at the Berlin Wall\",\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The uploaded video is ready for processing. This prompt instructs the model to provide basic information about the historical events portrayed in the video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "const SYSTEM_PROMPT = `\n",
    "  You are historian who specializes in events caught on film.\n",
    "  When you receive a video answer following questions:\n",
    "  When did it happen?\n",
    "  Who is the most important person in video?\n",
    "  How the event is called?\n",
    "`;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some historic events touch on controversial topics that may get flagged by Gemini API, which blocks the response for the query.\n",
    "\n",
    "Because of this, it might be a good idea to turn off safety settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the video, here is the analysis:\n",
       "\n",
       "*   **When did it happen?** This event took place on **June 12, 1987**. President Reagan references President Kennedy's visit 24 years prior (June 1963) and the 40th anniversary of the Marshall Plan (June 1947), both pointing to 1987.\n",
       "\n",
       "*   **Who is the most important person in the video?** The most important person in the video is **Ronald Reagan**, who was the President of the United States at the time. He is delivering the address and is the central focus of the recording.\n",
       "\n",
       "*   **How the event is called?** This iconic event is widely known as the **\"Tear Down This Wall\" speech** or **Reagan's Brandenburg Gate speech**. In it, President Reagan directly challenged Soviet leader Mikhail Gorbachev to dismantle the Berlin Wall."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "const response = await ai.models.generateContent({\n",
    "  model: MODEL_ID,\n",
    "  contents: [\n",
    "    \"Analyze the video please\",\n",
    "    google.createPartFromUri(videoFile.uri ?? \"\", videoFile.mimeType ?? \"video/mp4\"),\n",
    "  ],\n",
    "  config: {\n",
    "    systemInstruction: SYSTEM_PROMPT,\n",
    "    safetySettings: [\n",
    "      {\n",
    "        category: google.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "        threshold: google.HarmBlockThreshold.BLOCK_NONE,\n",
    "      },\n",
    "      {\n",
    "        category: google.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "        threshold: google.HarmBlockThreshold.BLOCK_NONE,\n",
    "      },\n",
    "      {\n",
    "        category: google.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "        threshold: google.HarmBlockThreshold.BLOCK_NONE,\n",
    "      },\n",
    "      {\n",
    "        category: google.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "        threshold: google.HarmBlockThreshold.BLOCK_NONE,\n",
    "      },\n",
    "    ],\n",
    "  },\n",
    "});\n",
    "tslab.display.markdown(response.text ?? \"No response text available\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the model correctly provided information about the dates, Ronald Reagan, who was the main subject of the video, and the name of this event.\n",
    "\n",
    "You can delete the video to prevent unnecessary data storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeleteFileResponse {}\n"
     ]
    }
   ],
   "source": [
    "await ai.files.delete({\n",
    "  name: videoFile.name ?? \"\",\n",
    "});\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Now you know how you can prompt Gemini models with videos and use them to recognize historic events.\n",
    "\n",
    "This notebook shows only one of many use cases. Check the [Video understanding notebook](../quickstarts/Video_understanding.ipynb) for more examples of using the Gemini API with videos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
